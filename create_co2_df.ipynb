{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd \r\n",
                "from pathlib import Path\r\n",
                "ROOT_DIR = str(Path().resolve()) + '\\data'\r\n",
                "co_df = pd.read_csv( ROOT_DIR + '\\co2\\Carbon_dioxide_Gt_CO2_yr.csv')\r\n",
                "df = pd.read_csv(ROOT_DIR + '\\co2\\CO2_global_CEDS_emissions_by_sector_2021_02_05.csv')\r\n",
                "df = pd.DataFrame(df.sum(axis = 0)).iloc[3:].reset_index()\r\n",
                "df['index'] = df['index'].apply(lambda x: int(x[1:]))\r\n",
                "df = df[df['index'] < 2015]\r\n",
                "df.columns = ['years', 'historic']\r\n",
                "years =  list(df.years) + list(co_df.years)\r\n",
                "ssp119 = list(df.historic) + list(co_df.ssp119*10**6)\r\n",
                "ssp126 = list(df.historic) + list(co_df.ssp126*10**6)\r\n",
                "ssp585 = list(df.historic) + list(co_df.ssp585*10**6)\r\n",
                "new_df = pd.DataFrame([years,ssp119,ssp126,ssp585]).T\r\n",
                "new_df.columns = ['years', 'ssp119', 'ssp126', 'ssp585']\r\n",
                "new_df.to_csv(ROOT_DIR + '\\co2\\\\aggregated.csv', index = False)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd \r\n",
                "import os \r\n",
                "import json\r\n",
                "import dash_leaflet.express as dlx\r\n",
                "path = r'D:\\Stage\\Climat\\Giec\\new_webapp\\giec\\data\\secheresse'\r\n",
                "\r\n",
                "def point_to_poly(point_geo,scale = 0.5, xscale = 1):\r\n",
                "    geometry = point_geo['geometry']\r\n",
                "    geometry['type'] = 'Polygon'\r\n",
                "    coord = geometry['coordinates']\r\n",
                "    list_coord = [[-scale*xscale,-scale],[scale*xscale,-scale],[scale*xscale,scale],[-scale*xscale,scale]]\r\n",
                "    list_coord = [ [coord[0] + a , coord[1] + b] for [a,b] in list_coord]\r\n",
                "    list_coord.append(list_coord[0])\r\n",
                "    geometry['coordinates'] = [list_coord]\r\n",
                "    return point_geo\r\n",
                "\r\n",
                "def treat_secheresse(path):\r\n",
                "    dict_df = {}\r\n",
                "    for file in os.scandir(path):\r\n",
                "        df = pd.read_csv(file.path,comment = '#', encoding= 'ISO-8859-1', delimiter = ';').drop(columns= ['Point', 'Contexte', 'Unnamed: 6'])\r\n",
                "        horizons = list(df.iloc[:,2].drop_duplicates())\r\n",
                "        print(horizons)\r\n",
                "        for horizon in horizons:\r\n",
                "            nom = file.name[:-4] + horizon\r\n",
                "            code = 'NORSPI' \r\n",
                "            temp_df = df[df.iloc[:,2] == horizon]\r\n",
                "            temp_df.columns = ['tooltip' if x==code else x for x in df.columns]\r\n",
                "            dico = temp_df.to_dict('rows')\r\n",
                "            geo_json = dlx.dicts_to_geojson(dico, lon = 'Longitude', lat = 'Latitude')\r\n",
                "\r\n",
                "            for element in geo_json['features'] : \r\n",
                "                element = point_to_poly(element, scale = 0.0357,xscale = 1.44)\r\n",
                "            dict_df.update({nom:geo_json})\r\n",
                "            with open(path + '/' + nom+  '.geojson', 'w') as f:\r\n",
                "                json.dump(geo_json, f)\r\n",
                "    return dict_df\r\n",
                "treat_secheresse(path)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "import plotly.express as px\r\n",
                "def rgb_to_hex(rgb):\r\n",
                "    return '#'+ '%02x%02x%02x' % rgb\r\n",
                "rgb  =[\r\n",
                "     (161, 105, 40),\r\n",
                "     (189, 146, 90),\r\n",
                "     (214, 189, 141),\r\n",
                "  (237, 234, 194),\r\n",
                "  (181, 200, 184),\r\n",
                "  (121, 167, 172),\r\n",
                "  (40, 135, 161)]\r\n",
                "[rgb_to_hex(col) for col in rgb]\r\n",
                "import numpy as np\r\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['#a16928', '#bd925a', '#d6bd8d', '#edeac2', '#b5c8b8', '#79a7ac', '#2887a1']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 5
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.3 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "e257e2ac680b0c6524c5b10c2f34a9e228b45559a7e5b127b50bb2044048af4e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}